{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up basic neural net classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[5 0 4 ..., 5 6 8]\n",
      "(10000, 28, 28)\n",
      "[7 2 1 ..., 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels)\n",
    "print(test_images.shape)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THE MODEL\n",
    "\n",
    "# 1. feed network training data\n",
    "# 2. teach networks to associate images and labels\n",
    "# 3. see if network's predictions are correct\n",
    "\n",
    "# Here is the general structure\n",
    "#\n",
    "# a) create sequential network (runs in sequence, not parallel)\n",
    "# b) create network layers (specify size and activation function)\n",
    "# c) define loss function\n",
    "# d) define optimize (back prop)\n",
    "# e) define metric to monitor training quality\n",
    "\n",
    "from keras import models\n",
    "# models specify the type of network. \n",
    "# Sequential makes sure that the model is not executed in parallel\n",
    "\n",
    "from keras import layers\n",
    "# a layer transforms input data to more 'useful' output data\n",
    "\n",
    "# (a)\n",
    "network = models.Sequential()\n",
    "# (b)\n",
    "network.add(layers.Dense(512,activation='relu',input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "# this model has 2 layers\n",
    "# Dense means that the layers are fully connected\n",
    "# last layer is 10-way softmax, which means it will return an array of \n",
    "# 10 probability scores (summing to 1)\n",
    "\n",
    "# (c)\n",
    "# (d)\n",
    "# (e)\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREPROCESS DATA\n",
    "\n",
    "# a) reshape data to what network expects to get \n",
    "#   * initial data has shape (6000,28,28) => reshape => (6000,512)\n",
    "# b) normalize data so all values are in [0,1] interval\n",
    "#   * initial data has RGB values [0,255] => normalize [0,1]\n",
    "# c) categorically encode the labels (see Chapter 3 for explanation)\n",
    "\n",
    "# (a)\n",
    "# (b)\n",
    "train_images = train_images.reshape((60000,28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "# (c)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 0.2538 - acc: 0.9262\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1030 - acc: 0.9689\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0678 - acc: 0.9795\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0488 - acc: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0380 - acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6e390056d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN THE BEAST\n",
    "\n",
    "# two quantities are displayed\n",
    "# 1) the loss function value\n",
    "# 2) the accuracy of the network on training data\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 44us/step\n",
      "test accuracy 0.9786\n"
     ]
    }
   ],
   "source": [
    "# TRY IT ON TEST\n",
    "\n",
    "# test accuracy is much lower \n",
    "# this is an example of OVERFITTING the training data\n",
    "\n",
    "test_loss, test_acc = network.evaluate(test_images,test_labels)\n",
    "print('test accuracy',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors defined by\n",
    "1. Rank (number of axes)\n",
    "2. Shape (tuple that described number of elements along each axis)\n",
    "3. Data type (the data type of each element, such as float32 or char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalar dimension 0\n",
      "11\n",
      "vector dimension 1\n",
      "[1 5 3 2]\n",
      "matrix dimension 2\n",
      "[[1 5 3 2]\n",
      " [1 5 3 2]\n",
      " [1 5 3 2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# scalar (0D)\n",
    "scalar = np.array(11)\n",
    "print('scalar dimension',scalar.ndim)\n",
    "print(scalar)\n",
    "\n",
    "# vector (1D)\n",
    "vec = np.array([1,5,3,2])\n",
    "print('vector dimension',vec.ndim)\n",
    "print(vec)\n",
    "\n",
    "# matrix (2D)\n",
    "mat = np.array([[1,5,3,2],\n",
    "              [1,5,3,2],\n",
    "              [1,5,3,2]])\n",
    "print('matrix dimension',mat.ndim)\n",
    "print(mat)\n",
    "\n",
    "# and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating tensors in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(60000, 14, 14)\n",
      "(60000, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "# re-read data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# selects 10-100 (100 not included) digits from data\n",
    "s = train_images[10:100]\n",
    "print(s.shape)\n",
    "\n",
    "# generally you can select range along any access\n",
    "# e.g. select 14 x 14 pixels in bottom right\n",
    "\n",
    "s = train_images[:,14:,14:]\n",
    "print(s.shape)\n",
    "\n",
    "# negative indices are relative to end of axis\n",
    "# thi example crops to center of image\n",
    "s=train_images[:, 7:-7, 7:-7]\n",
    "print(s.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example: relu transformation \n",
    "\n",
    "output = relu(dot(W,input)+b)\n",
    "\n",
    "1. dot product W . input\n",
    "2. addition +\n",
    "3. relu operation relu(x) = max(x,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A) tensor addition from scratch\n",
    "\n",
    "def naive_add(a,b):\n",
    "    # a and b are 2D tensors\n",
    "    assert len(a.shape) == 2\n",
    "    assert a.shape == b.shape\n",
    "    \n",
    "    # don't overwrite original input\n",
    "    a=a.copy()\n",
    "    for i in range(a.shape[0]):\n",
    "        for j in range(a.shape[1]):\n",
    "            a[i,j] += b[i,j]\n",
    "    return a\n",
    "\n",
    "# B) just use numpy \n",
    "# addition z = x + y\n",
    "# relu z = np.maximum(z,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnU2MbFt13/+7uuu7P+6lH/c+xItxoowRSmQmRHJbtiwU\nWSLygBCiyNiR5UFIrDgDMJN3X5SBYYBELHkQghFYRv6SHPAkwVbUiojkgB2T4BiMpeRhY/Mu7351\nd31XV+0Mutbp/1m196lT36e71k/aOqfqVnWd7lv/s9Zee621nfcehmHsFqVtX4BhGJvHhG8YO4gJ\n3zB2EBO+YewgJnzD2EFM+IaxgywlfOfce51z33LOfds595FVXZRhGOvFLbqO75wrAfg2gB8F8DcA\nvgbgA977b6nXWaKAYWwJ770LPb+MxX83gL/w3n/Hez8E8BsA3hf58GS8+uqrqcdFG3Z9d/f6inxt\n67i+LJYR/tsB/BU9/u7kOcMwCo4F9wxjB9lf4r1/DeAH6PErk+emePToUXJ+7969JT5y/Zyenm77\nEjKx61ucIl8bsPz1nZ2d4ezsLNdrlwnu7QH4c1wH974H4KsA/on3/pvqdX7RzzAMY3Gcc/CR4N7C\nFt97P3LOfRjAl3E9ZfiMFr1hGMVkYYuf+wPM4hvGVsiy+BbcM4wdxIRvGDuICd8wdhATvmHsICZ8\nw9hBTPiGsYOY8A1jBzHhG8YOYsI3jB3EhG8YO4gJ3zB2EBO+YewgJnzD2EFM+Iaxg5jwDWMHMeEb\nxg5iwjeMHcSEbxg7iAnfMHaQZdprG1uA+xfOOudj1rl+PXDdr02fh57LOo/hnEv9TB553mssjwn/\nFjJr66TxeIzxeJw658ej0Sh15HMgLcZSqTQlztBzecXrnMPe3h5KpVLqKOd5bwDGcpjwbyEiYH1k\nEWeNq6ur6PDep0SZZ8jNQM6zKJVKKJfL2N/fx/7+fnLuvUe5XJbOsMnr7SawHkz4twy27GyxWfAh\nQQ+Hw+Q4HA4xGAySI5977xMLHBsxa723tzdTqPv7+6hUKsmQG5d4AnpaIf9mrBYT/i2ELXzImmtx\na6H3+330ej30+/3U6PV68N4n1nhvby8558dZx1IpO168v7+PWq2GarWK0WiUEv14PE68Bha8iX/1\nmPBvISHhs2UXcYeOvV4P3W43OfLo9XoYj8eJCy5uuD7nm4F+bpbwy+UyhsMhRqMRgJs5v3gC8vtp\n8RurxYR/y9BBPO3as0UXq87n3W4X7XYbnU4nOfL5eDxGuVxGpVJJHfV5bMwSfqVSSYle5vza7Tfx\nrxcT/i2ERc/uvRxF7Nqid7tddDodtFqt6BiPx6k5eLVanToXocrgx7OEX61WEzGL6MUD4KVFc/fX\niwm/YMxaZxerHhrD4TAqeBntdntK7JeXl1PCDwk+NPRNYJbwa7UagLSLXy6XUa1WMRwOkwBfaPnQ\nWB0m/IKh5+96vV3EzQE67dJnjZCr3+v1khvHeDxOWVn5XB1DWNTVr9fryY1MVgJ4KsFLgzJ4idFY\nDSb8giHLdDxv58cyT4+NULSeRyiwJ+8R4ct18HRCVgd0cE8/niX8Xq8H4Eb08jMqlQpqtVpqiVAG\nMO36G8thwi8gYmFD6+29Xi9lrdvtdupcrHds6OU7fjwcDhNrrGMI+/v7iSseW8rLs5zX7/enRF+t\nVlGr1VCv11NLiDzfn/VzjflYSvjOudcBnAMYAxh679+9iovaZdjih4Ta7XZTc3I9er3e1Bq+HrHk\nHRH+eDzG3t5ech2xBJ7Q41kWud/vR0Xf6/Wwv7+fSjEGboTPGX3Gcixr8ccATr33z1dxMcaNi83C\n18G5i4sLXF5e4uLiYuq81+tlpuSGsvl0yq5Y+7wpuzp9N4vBYBAUfafTQbPZRLlcTi3ryU3FRL9a\nlhW+g5X2rhQWPkfpxZW/vLzE+fl5arx48SI573a7M3P1YwU6sr4+Go2CxTh5C3aykMCgiL5Wq6HR\naKDZbKLX66FSqUyJXnsAxvIsK3wP4PedcyMA/8F7/+kVXNNOE3L1eRnu4uIC5+fneP78OZ4/f44X\nL16kzrvdbip/PzRiS4ah4pjYcdZzMYbDYcrSNxoNdDqdJMhYrVYBpIN/ssZvrI5lhf8e7/33nHNv\nxfUN4Jve+6/oFz169Cg5Pz09xenp6ZIfe/eJldrqwB97BK1WC51OJ1i1J+fbplQqJd5Lq9VCs9lE\no9FAo9FAvV6Hcw71ej3xQvTSn5DnxrRrnJ2d4ezsLNdr3arupM65VwFceu8/qZ73drfOz2AwSCL1\noXF+fo6nT5/iyZMnePr0aWo8efIkJfxQXf62aTQaeOmll3BycoKXXnpp6vzo6AjNZjO5IfCx2Wym\n1vp1ObAl+qSZLIEG/yALW3znXANAyXvfcs41Afw4gNcW/XnGDZzYUqlUcHV1lQh4OByi0+kkFW6y\njs7185KEI6NIN175Hfr9PjqdDi4vL5P1f+994sVIUZFuEDIajaKrC7bOn59lXP2HAH7XOecnP+fX\nvfdfXs1l7S5iuWQtW4pXhOFwmATFJE2Whb9IV5xNwisW3W43le03Go2SuIasOOh6fS4btrX+xVlY\n+N77/wfgXSu8FgM3X2Cx+Ho9ezgcol6vo1qtpiw+u7whsRfF+ku9gVh8sfSj0SiVSCQZi3LtEugD\nEPy72Dr/fFjmXsHQwtfBLRG+WHzt6ocaWRYJsfiSwQcg5QH0+/1E9JyjL9MemcqY6JfDhF9AxNVn\n0Ytry8LnMtlQVVsRI91s8fm81+uh3W6j3+8nU5tQai8n8+i1fhN/fkz4BYO/zMD0l59d/SyLX0TR\nAzcWX9x7yeSTAJ20/9KdearVKhqNRuLu89+Jb5JGPkz4BYQDVdqqydxeAnz6sUTCubIPmK7tn/d6\nQiwqNnHjpcfecDhMxSg4uUeOkrIsnXhZ9JbZNz8m/IIRi8rLjYDnu7VaDc1mEwcHBzg6OkKn00kC\ngFx8I+/Vwo8JJRQj4PNQ5l/Wz2N0Vx1OUAIw1VWIW4l1u91kns9lwbzkZ+TDhF9QtOjFOoqVEyvf\naDRwcHCAw8NDdLtdAEhV84no9aYZWoChz4/l4YeyCue1tnyzkN+NaweyhM9TH7lRLOrN7Com/ALC\nTSdY9H7S814CXeIGHxwcJBFx5xw6nU6yxOecS8Q0HA6n3HZuasmfr7PhxBUHMJURqCPts9B99eRn\nSoJOqBeBiF+WMCXeIdMZs/jzYcIvKCxQET0LX1x9Eb6sfzvnUp1wOLdfp7TGRM+ehh78GhEbt+ua\nB7b6/DOzLL4Iv1KpTAnfLH5+TPgFRVe8ifB1LXuj0UjSW6+urgAgNacXSy/r5uxNyGv4M/gzReyc\nHgvclO3K+zkOkHeez+f8s7Lm+OzuizfA2X1Gfkz4BYTFyefa4tfr9ZTo2d3VzTzY9Qem21XPsvrc\n/47fI2Nei6+Fyi5/aHMQKU+WGx4L3yz+/JjwC4q2+ACm5vhi8bXV4zm9CEYLX35e7LNDopc1dH6/\nzPOXdfXlc3VzT7b4sp5fr9dN+Etiwi8YWQLiAh4WATeqkGw4rtWXeTFXsYVq9LXbHhK/pNHKcVHR\nh4jlGuhriS15Fi1ZqciY8G8ZIfFzVFuKXWRO3Ol0UhticO98Ds7FXP1YToEu/V3l76cDmPV6Hc1m\nE4eHhzg4OECz2UxlL+Zp622kMeHfMnQqK1v7UqmUCF+68uj0Xk54kaw+ILxFVWiur5/Xr13W3Y6l\n6kqi0uHhYSL8Wq2WSlk2i58fE/4tQ1t8blIhLbG5OSfX7otIZC4txEQvRy30eRtsLvP7aYvPwtcW\n34SfHxP+LYRz1IF0x57xeJyIvtFopPL5xeLrDDxx3YXQPJ/Thtc5r9YWP+TqS48+uaGZxZ8fE/4t\ngy0ikBZ9tVrFeDxOGlnW6/VgJR8wvRQXc921q88Zheu4AcjPljl+yNWXm4FZ/MUx4d8yxCICadFz\nn3zpXivzYG7TVS6XAaSX4kKimRXcW1cUPY/FFw+Gb2gW3JsPE/4tg4XnvU+69LCQtTusLT4Xw4RE\nHJrfx4J725jj8+66FtxbDBP+LWOW0HR9vrj7ciMYDAZTTTvkpiEBPxa5oCvy9FglOndARM5ei96o\n00Q/Hyb8Owavg+sKvqOjI3jvU+v83KgTuF7T13NmSaMFbhKEdMbcOrLmdM3/oj0AjGlM+HcMLXxp\n1nF4eJjsTS8pvNpF1ptlijfANfwsfEkVXrX4Q81CskRv4p8fE/4dQ2e+yfxYNqkAEJwXi8DFsrPr\nLMKWZKHQJpyrFp8Wf8jq69cZ+THh3zFCrn6z2QzW62vRS7ntrPl8aMfddbn6sRuAPDYWw4R/xwgJ\nX0Qf2v6aLf1wOEzdBPS+e/I8P7fOIJ+QJ6BoN4H5MOHfMXgdnOf4IlJt6XUZrA7k8Y2AN7pYd2Rf\nmOV9rPOz7zIm/DtGyOLz/nOhOT037OB23DqqL16D/LuwCTd/XZ+zq5jw7xihBBgWPnAj+pDl3Nvb\nSzre6A69m4CnEeKJcBeeXq8X3EJLNwkxsrG/1h2DhRAq3eXlOW7XLXnx7XY72bxChmxuCSCJA6zL\n5Zbpx3A4TBqJtNttXFxcoNFoAECSnCS/lwQszSPIjwn/jiHC52o9Lt3l14Vy4tvtdlLkIwUw7PID\naausz5dFhC9WvtvtotVqJbvqAECj0UiJXm8waszGhH8Hydptl9NhQ11uWq0WLi4uUlVvIm6x9no5\nDwi36l4EtviylbZY/EqlAgBB0bNXY8xmpvCdc58B8BMAHnvv3zl57j6A3wTwDgCvA3i/9/58jddp\n5IRd/dA8WMSv+/Y1Gg30ej3U6/WpdlYS0ZedbKXTj3Mu2QBzVbnykhnIrr54H1xZqIOYJvz5yGPx\nPwvglwF8np77KIA/8N5/wjn3EQC/OHnO2DLs6vPj/f19XF1dpeb+YuklcNbv91Gv16dEL9a3Wq3i\n6upqanWA4wbLoi2+9NHn0lsWfa1WS1YbTPj5mSl87/1XnHPvUE+/D8APT84/B+AMJvzCoHfa1Qk4\nInppUc3bVdXr9aDoJcg2GAymVgd0QtAy6Dk+bwfGlp69FRP+/Cw6x3/gvX8MAN77N5xzD1Z4TcYS\n6G45HM0XoYrlloQcLrqp1+tBq9tut1GtVjEYDKZ+Hu+ssyz6s/V2YM65aFaiCT8/qwruZf7FHz16\nlJyfnp7i9PR0RR9rLIKeDvDz0uSCq/d0s45Qt55VoWsCdGYhb6Kx7lqB28bZ2RnOzs5yvXZR4T92\nzj303j92zr0M4PtZL2bhG+tF59brwam3oePl5SUuLy+TZb1Op5NU9ol1FQu7juo87vgjNx+x8Lrd\nlm7Gsetoo/raa69FX5tX+G4yhC8B+BCAjwP4KQBfnPMajTXCAg+JO+bmi/BbrRZarRY6nU6SxCN7\n9InF5UYcq67H10uO3HhTtwq3RpuLkWc57wsATgGcOOf+EsCrAH4JwG87534GwHcAvH+dF2nkR1fb\nhYYWOz/XarVSFr/b7SYWfzAYYDAYTFn7dVh83q+P8w305iCcm2Diz0+eqP4HI//0Yyu+FmMFaOGz\nYNlVZ8Hzc2LtxeKLq9/r9RKLz8k7XK23KkTIvPQoFp+3A2NX30Q/H5a5d8fQpbayeaYWr/YA5HyW\nxRfh65TdVYlfW3zt6us5Prv6Jv78mPDvINriSwZcp9NJWX1ev5fRbreTeX5sjh+r7FsVPMfPE9wL\ndQU2sjHh3zG0qy8Wn912EbBMAfgGIAU6oai+vJ4/i4+rIBTV164+bwfGrr5Z/PyY8AtGVoOLkJXV\n1rff7yei5SFi7vV6U5aexd/pdJLXspsvU4JVpeZmoa09R/Q5wMeuvln8+TDhF5CYGy3zdx2V5yHC\nFwsvQ57Trr6O/vd6vcTNF++AW26tG04uYmtfq9WS0lwtfttUY35M+AVEW3MOpIm4ZXB3Gp7Py5ye\njzJXD90w5CYg+fF6WrBJ4XOvAN4fILYJqEX158eEXzBY9DrjbjweYzAYBEXN4hYXXR+1BQ8d9SqA\n3Cg2mRar+wWw8EP7AZrFnx8TfgHRfed48DycB0fixfLzVllyLtY79LO57l48Cbb4myCUrsslxOzq\n68i+kR8TfgEJFamIVeZ2VOfn56lxcXGBdrsdnALIY7HenHXHQyf2cHrutub4MVff5viLY8IvGNrV\n18E8cfWlRdbz58/x7Nmz5Cg183pI1F465ujkG94mK+QNbMPVj83xQ7vmmvDnw4RfQHStu4if6+PF\n4j9//hxPnjzBkydP8Oabb6LVakVz9Gcl32R1z111kk4M3SyULb5E9WUNn9fyTfTzYcIvIFkWn7Px\nZK5/eXmJi4sLnJ+f4/LyMlh8I4+5OWboWBTy5Cxs6mZ0FzHhF4xQVJ8tvk6xDYlcV85xi235DD4W\nCc5V4KxDucGVSqVUBp+047JNNebD/lIFRAf3WNyh5Bv+dw4E8tw85Nbz5xUFbr0VEz4HG0NdhY3Z\nmPALSGg5L6u2Xrv0IYt/G0QPpC0+T2mkt7609hbRSxBwU8uNdwUTfsHQc9qYxdd19KHOOKEOOUUW\nPXBz02OLL8HMWq2Gvb29KUtfqVSs796cmPALSCiin+Xqa4uv5/ahIFhRRRKb40vSjkTwWfTWZXd+\nTPgFJOTqZ4lfj9ga/W2IgseEz5tq6N2AN5lgdFcw4RcMnodnufpZvfSylsKKDrv6PMfnnHxO49XN\nQYx8mPALDDel4I0ydCNKEYIcQ6m4sqPObRBHaAmz1+uhUqlMtRDjqY2RHxN+wQh1n2HBDofDYOdb\nsfaVSiXo/ouQQuv5RSLkqehpz6z4hTEbE37BCO1vL19s5xxGo9FU80ve4KJcLkfz9LVQeA+8ohGq\nWQi19b5N8YsiYcIvIFykwiKVNWzdLZeX8Pb391P19DJNkMq7kMVfxWaXqySP6EPJSUZ+TPgFQ1t8\nfk5uBDHRA8De3l5qh1ngZs/5UAVbEQUTc/WzkpOM+TDhF4zQ/vZi/SViz4EtXTIrNwhZ75blscFg\nkBK+JMHweREEpFc1dE5DaAcfs/jzY8IvICJeuQGwdXPOTQmeXXZuNy1WcjAYBPeYK6pY8gb3TPSL\nY8IvGCJMWbNmC+i9TxWp8Jefl/sApETf6/Wwv78f3eZafn6RyJrj2w1geUz4BWPWxhDee9RqteD8\nXt4XquWXmIDkumeNZZj1s/P8fF1QlJWFaIJfDBP+LUPnqUvKKjfYYCFwwk+5XEav18sU0CIi4vfo\nNONQmbB+jwl385jwbyHciJJFr+fwWvSVSgX9fj8len2ehyyhcrad3qqLrTj/rKIEFncJE/4tQwJ4\n5XI5ZUE5ICiPtehF+DHXeZGlMf162Y2HB68uhHIHTPybZ6bwnXOfAfATAB577985ee5VAD8L4PuT\nl33Me/+f13aVRoJ29YEb0XMhS0j0tVotZfFjx7yE3HXZeFPnEkgzkdtWJnxXyWPxPwvglwF8Xj3/\nSe/9J1d/SUYWvK4PpHedkU0mYqKv1+tJ6i6Lfd6899j8XHIMpN+9Fr309c/6ecZmmCl87/1XnHPv\nCPyT9TPeAmLxpTZdLL24/ZVKJbjhpPSk55z9PA07Qui5Or9Hlg5DouclSg7yFblm4K6yzBz/w865\nfwbgjwD8G+/9+YquychALL5Yer30Va1WUzvQVKvVRPSNRiNxt2Mjr/hi4u92u1MZg71eLzUNkUQk\n+X34/cZmWFT4vwLg33rvvXPu3wH4JIB/Hnvxo0ePkvPT01Ocnp4u+LHGrHV+sah611luU5Ul+lkC\nDLn5fKxUKlO19LyLLxfY6E7A+vfS1xcr1NFD/72yHt8lzs7OcHZ2luu1Ls+dduLq/54E9/L+2+Tf\nvd3NN8fV1VVqk0x9jLXmWpWr3+l08OzZs+hot9vR/QCkkEh2zAmNe/fu4cGDB9HRbDZTN8fY+S4w\n8byCv3Bei+9Ac3rn3Mve+zcmD38SwJ8ud4nGKuGyXl3Pz625Ytlws8iy+s65qV4APEqlUurfOcVY\n0BZebhD7+/szew6ORqNE4LqDkXFDnuW8LwA4BXDinPtLAK8C+BHn3LsAjAG8DuDn1niNxhxwzr6u\n59/b24tusjFv5l4ssl8qlTJ3/CmVSuj1eqn97kTkPN/nUlwR/t7eXvSGor0G/juMx2MTvyJPVP+D\ngac/u4ZrMVaEiJxFz5V+MbEvKnx+LMKPiZKDk/K+q6urVBmxCJ8tvha97kmghS9lzXJN8nNN/NdY\n5t4dI6ueX9fuhwS/aAKPoIXPefqy2w2797pXgBa+iF7+PWbx+bP0dZnYpzHh3zFE+HKu6/mz5uf6\nPC/a1Q/t7KNFKcIeDoepra5Z+PwaEW9I+Nris7Xnn2ncYMK/g/AcF1j9ltix93vvsbe3l2v3Xk7s\n4YQf+TnyGvldWPjs6odWBoCbCL7M7034aUz4d4ysZhurIEv0wHWmnuQNSAuweQNrHHvIWsfXa/n6\nfTy3N9KY8I2l0KJia8473V5eXuL8/BwXFxdotVpot9vodrvo9/tJe3CGbxR6HT7P2rzN67Mx4RsL\nE4sXSMuvfr+PbrebEv75+Tna7XZQ+CHLrD0YLXr9utB7jWlM+MZCxAKDsvYuFl+2uGbhd7vdZEjF\nnk40ih1nPbdLKbrLYMI3loZvArxEpy3+xcUFzs/Pk12AeDegPBZ/GetvpDHhGwsTcvXZ4vf7/eAc\nP7QGr4WvhTxrnh96T+jcuMaEb8yNFrxOBOJy3NAcP9YuW2fWadd9ltj1YxN8HBO+sRChlF09x48F\n97LqBGJBulmW3gQ/HyZ8Y270+jqvo+tGm3r0+/3Mn80VddJCTLoMVSoVlMvlZHCugOQLcMJPLAZg\nmPCNOdEbdejx4sWLZK2+0+nMXK4LwWKvVquo1WpJN6GDgwM0m000Go3kebkh8E1A3wiMNCZ8Yy54\nnV7X3Q8GA5yfn+Py8jJZp5ctvfMKX6w9tw/jnoEifHlcq9WCwmfRm/inMeEbcyHBO5nDa1deC39e\ni8/CF4sv/QKbzSYODg7QaDSiFl/y/nlot98w4RtzooXf7XbR6XSSZTtx9bXwpfPPLLiMmC0+C58t\nvkwBZN7PtQG6wMe4wYRvzIUWfqfTQavVSoZY/FartXKLL6LnOX7I1dctt0z805jwjblg4YfW6V+8\neJG4+osG9/QmIfV6PbH27OqLxY8Jf1Yhzy5jwjfmghN0xNVvtVpJOq5k5y0zx2dXX6x6yNWPzfH1\nzzOmMeErsr6cOic9KwllVhFJ1vk2Cf3+/FwoQUfc/YuLi9RSnqzb8555s9CuPu8EpN18LXoJ5hmz\nMeFHiJWcyhef17J1aykdVc47uGXUtgn14ZOlPI7oi/Db7XYyz+90OlPWft45Pu/9xwG+kKVfpNnH\nrmPCD6Bzz0O15qEhW1DLXJPXlfVz+t+A6f3tt0VWSm1oh5ws4Q8Gg6my21nwvgAifN4GjIN6vIRn\n5MeEHyH2xZf5rSSn8LHb7cJ7n7ieOr2UH/MA0vvFbxvdwiqUh89zfK7A48QdXsrTW1vF0K4+Z++Z\nxV8dJvwAsS8+W/xer5d0kpFWUu12O9mxVr6Yesjz0isOuAloFQn+3Tkfn4XPNzy2+Lxll1j8RVz9\nUPYeR/M5km8Wfz5M+BG0pecvvlj8drudBLSk0cR4PE7ll+ujiEBErze62Dax35ubXc5y9XUq76Ku\nPs/xRfSNRiNJ2mGLb0t282HCV4RqzfWXX4QvkewXL14kYzQaBTd7DAmALVu5XC6E8AX9u+t97Nji\na+GHWl7PG9WPZe/V6/WU57RoJ99dx4QfIGbxxOKLpZN57YsXL/Ds2TM8ffoUo9EosUzNZnOqvZR2\n7+XLnXcOvAliotdLeTGLr7ex5l10ZhFbzmNXP1SWa67+fJjwA3DpKR9Ho9HUl1xcfbb4sc0e9LKW\n/pLzjjHy75p5mknGGmKGXiPnoeVKvn6O3MuQYJ7M7WPbb/PvHWullRUbYSuvRW8Wfz5M+Ap253XJ\n6WAwQKvVSkQueemcoirC5saTWkQsBhE/z/XzdpONJQHFApOzBoDkZiVDb1d1fn6OZ8+epYpxuPR2\n1tbb4unI78sNN0qlEg4PD3F4eBhM1LF6+9VhwlfoyL0el5eXeP78eSo9VaL6MeHzvJj3pweQEr3M\n80Otpnhw8Ql/8WVJMBSN151yYkcO3HE3XBkXFxd4+vQpnj9/ntzwdM09i17+ptrLYVedlzuPjo6C\nabk6gm8lt8thwlfwWj3PX8WtZbdeovla+KFgmAiKXX0teha+Li3Ve75zeqq2etrb4Dm63sNOj+Fw\nmHLdeXS7XVxeXqYsvqTmcgwj5EkIOrahlz4PDw+nuuxkNdowi78YM4XvnHsFwOcBPAQwBvBp7/2/\nd87dB/CbAN4B4HUA7/fen6/xWjcCZ6dJAE82hODe8GzxtasfioCL5ZRNHUOir1QqqX+bld6rXWi2\nsHwNOk6hbwR8PhgMUnN3PkpOPk9zJGFHu/pyHTFXnxNzeMlTW/zQmn2sv56RnzwW/wrAL3jvv+6c\nOwDwx865LwP4aQB/4L3/hHPuIwB+EcBH13itGyFk8blDrATzeP1eAl7tdjs1n2dLLxHwq6urqOhr\ntdrUnF+fyxdfkC+9Fpted9dBOn0jkMf9fj9JRtLJSRzU5NgGW/yYix8KaHIBjqyEiMUPZemFgnmh\neIcxm5nC996/AeCNyXnLOfdNAK8AeB+AH5687HMAznAHhM9JOrxkd35+nszt5UuvRS8Wn4UvohdX\ndjQaJeLVohfha5Hv7e0l79Pr4SKkUHQ+dBOSm0CsYabEMUTc+sjTHhk6uCfXwNfD18vJObI+L1ae\nLX7M1bd+essz1xzfOfeDAN4F4A8BPPTePwaubw7OuQcrv7otkGXxnz17hvPz80ToLHot/OFwGGwJ\nLQLmOS6vU4s1ZNHL0PvLOeeSubnM92cl3bD4Q0eZx2vPRgaX28pRgoAs/BihenvJeTg6OkpF9bOC\ne2btlyO38Cdu/u8A+PmJ5ddpWNG0rEePHiXnp6enOD09ne8qN0xWumqegJnM4+VnsfhKpdJUyilH\nuIfDYWbV6/pCAAANLUlEQVQ1H0fCORoux/F4nIop6GNM+HIuN7qY8GU+r5c5Q6IP5Rzo+b3U2R8e\nHuLo6GjK4seKcUz005ydneHs7CzXa3MJ3zm3j2vR/5r3/ouTpx875x567x87514G8P3Y+1n4RSfL\nIklyil4v15ZVLDS/TjLXOM+fy0llLl6v12eKXoudz733U0txfJQlRR4cA+j1eqkeerpjLicncfGN\ndudjuQY6Bffg4CAR/b1793B8fIyjo6OUxZf5fWx507hGG9XXXnst+tq8Fv9XAfyZ9/5T9NyXAHwI\nwMcB/BSALwbed+vgdWbd/UU6yQBp0bOA9Do7gNR7ON1XRC/LaP1+H7VaLSp4zuufR/j8WAf69Hyf\nN7rU83iur+diI71ur3MMeE4eapl9eHiI4+PjZHBvPRF+yNrz/5kxH3mW894D4J8C+IZz7k9w7dJ/\nDNeC/y3n3M8A+A6A96/zQjeFtvjyJdXr1KHg2WAwCNbVs8V3zqHb7aZEL5a20+mgWq1GBR+z9ix+\nFn7oBsDBPR3d56Amr+Xzxhj6/Sx++f1C+QYi3FkW/+joaKqZJrfWimUrmvjnI09U/78DiBWL/9hq\nL2f7hJabQskpOitPhA8gM0POe58sx4mlF9G3Wq1ULroWvMyPs5p6jMfjKeHz4FZYocErEaGjeD1a\n9KGVBr0ysbe3N1VmKw00j46OEjdfXHzdaSckfGMxLHMvgF5u0vn1IUsvllJH04Hp4hfgZk7f6/VS\nxSgc6AuJP0v0WcIXV52tdSiBR64rFPjjG2AoDVinG7Pg5XcJbZKhLX6oSIeFD9h22MtiwldoV5/b\nRskXLLROL/NzFryIiW8W8rzM6We59SGLP4/weclNEohiqbv6BhC7QXBGXtb8nuvq+abFSTva1T88\nPJya0nBfPRP8ajDhK7Srr+vnAUxZehFVtVrFcDgEcCN6WWsX4YvodRCQxRIT/ixrL8G90Dp7qNV1\nluWeVcUHhMt+5W8lv09oq+us4N7h4WEwY9Hy8leLCV/BwhcLyoUzktbKgS/ONxdRxyLPvPzF5zJC\nVjJkNWNNPGfN8XnaEjoui1y/LsCRo8zjJVGH1+wloKdXBUIrJcZymPADaDeVBTEcDpMEHL13u/TU\n09Ytli4biqqzFWWvQWIDQijBSN4f6nkXWnoL5dLPQ2i+vb+/j2q1moiYj41GA8fHx3jrW9+Kk5OT\nZOlO2mnZ9lebw4Sv0G6qLJEJLPLQEBFLeq4Wue7Lr7Pf9PyZRR8qxJGgoXgGUlMfutmEmmOESmfz\n/I30Uc739vYS4cv8XSy7uPRvectbcP/+/WROHxO+CX59mPADsPB1VdnV1VXU2tdqtcxad16+4wEg\nsexa9Jz8I9cjP4uLd6TqD0A0SUcvvS1i5flvFBIpW/zDw0Pcu3cvGZykI8t3kqhTqVRSPQbsBrBe\nTPiKLNGLwLIsvq5O08fBYIB2u41yuTyVrsvC5zm3jgGIa68DX3LNoSnEKi2+/E1CIyT8k5OTZBwf\nHyd74Mkafsjiy2fw5xmrw4QfgAN8LHpxq2PWvlqtTq1l68FLeEB6aY8r7DjoJmW34gWI0Lm2X57X\n1XmhpTv5jNAx799HjjrwxsKXJbqTkxM8ePAADx48wPHxcSo5h5N0soRvrBYTviL0ZWYhzrL4wE1k\nO9REo9/vJ6IXSy83A/6ii8jl87XYYkPeq9fY9Xp7aFlukb+T/ntpi3///n289NJLePjwId72trfh\n6OgouioRapNt4l8PJvwA3NiCrTBwLdaYta9Wq8mXP5aIw3N6KYrpdrtT1XxyzHJ3syxjzKIvM6+X\nz4oNXsrTrv6DBw8S4WsvxZpqbB4TvmKWm8ldcyQRpdfrodFoJNF5nXXG5xL515l/khMwi5ilzrLk\ni87jQ0gik07FlaOO4suQWvujo6OVXIexHCb8OZEvPtfqc7nucDgMJt5w9ppeZuM5uHgEMWLZdNqt\nj6Xjzvu76nNOzgmN+/fv4+TkJFmqk9Ja7j1gbB8T/pyIKy8555zLLwG3UNssbq4ZE72k22ahhR1K\n5AklCMl781r+UJBNfnfuU8CjVqslrj0LX0qNzY0vDib8OdEWn0VfLpcT4cfq0eU1sbLWPMLPqqzj\n6jrekkviBXmEH8qckyG/e71eT9Jt+Xh8fIyTkxPcv38/6Z0nNfUm/OJgwp8Ttnosen6OA1U6iMUZ\nfTrSDgD9fj/z87m8N2TZJW7AgbJF8/BDATwWvjTI5Fr64+PjVFYeW3xz9YuDCX9O2GWXxxK0q9fr\nqWW4kNXc39/PbGCRR/ihzDx5bjAYBPv9zRsxDy3V8U2PhX///v1kyA1ACnF4jm8WvziY8OeErZ4E\n7KQ4RwQd+4I751IVf1r0pVJppvB11x89dCKQeAh6J95Zv6McY8t1tVot6Zwja/U6M08Kc8zVLx4m\n/DnhdfrxeIxKpRKtWQ8dQ8LnqUAe4XNhjy704YxA7qM3r5sdEj0LXyy+uPYnJyd4+PAhjo6OUhl5\nkt9grn6xMOHPCbvwvJWVEMuF5+fq9fpU/rz8bOnbFyMkfBZ/r9cLNuGUozQKyfr9dOMLfiwBvOPj\n41ThDbfGljwHbifG0w9j+5jw1wRH0PkLz00+ZIrAzT5mCVNH7UOu/sHBAbrdbnDkFX7s2Gw2cXJy\nkrj23Bm3VqtN3XC4LbZRHEz4a0CLnlNv2V3Wopfqvyy4rl9vhsHtsbn9Fj+e9fNjQT05r9frSdSe\no/eybBfb0tqEXyxM+GuERc9Ve2zx5QYhgcJZwuS5e2hJT/cC1Oe6k0/omrNGrVZLUnD5yJtfcKYi\nTxlM/MXBhL8mQqIH0suBbOllXjxLmDpDL9QVN2sqkGc9PyR4eb5SqSQRe33Uu96YxS8uJvw1okUv\ntfXSzktEz628Zwk/Kx8/K2VXpgJ5M/fkqNN2ecPL0FEajISGib84mPDXjE6ZFUuoRS+CnSXMPEU6\nsU0vdMJQnuvW53o3H30M9c0z0RcPE/6G0FbUe59Yfr3cN4usGvvYUqJ+3TK/Q6iGXu8RwK/X58b2\nMeGvmDxfcBOBsW0slcowdhATvmHsIDOF75x7xTn3X51z/8c59w3n3L+cPP+qc+67zrn/ORnvXf/l\nGoaxCtysgI9z7mUAL3vvv+6cOwDwxwDeB+AfA7j03n9yxvv9qvq9GYaRn0kQORhQmhnc896/AeCN\nyXnLOfdNAG+Xn72yqzQMY2PMNcd3zv0ggHcB+B+Tpz7snPu6c+4/OueOV3xthmGsidzCn7j5vwPg\n5733LQC/AuDveO/fhWuPINPlNwyjOORax3fO7eNa9L/mvf8iAHjv36SXfBrA78Xe/+jRo+T89PQU\np6enC1yqYRhZnJ2d4ezsLNdrZwb3AMA593kAT7z3v0DPvTyZ/8M5968B/JD3/oOB91pwzzC2QFZw\nL09U/z0A/huAbwDwk/ExAB/E9Xx/DOB1AD/nvX8ceL8J3zC2wFLCX8GHm/ANYwtkCd8y9wxjBzHh\nG8YOYsI3jB3EhG8YO4gJ3zB2EBO+YewgJnzD2EFM+Iaxg5jwDWMHMeEbxg5iwjeMHcSEbxg7yMaF\nn7deeFvY9S1Hka+vyNcGbPb6TPgKu77lKPL1FfnagDsufMMwto8J3zB2kI004ljrBxiGEWVrHXgM\nwyge5uobxg5iwjeMHWRjwnfOvdc59y3n3Ledcx/Z1OfmxTn3unPufznn/sQ599UCXM9nnHOPnXP/\nm56775z7snPuz51z/2WbuxdFrq8wG6kGNnv9V5PnC/E33PZmtBuZ4zvnSgC+DeBHAfwNgK8B+ID3\n/ltr//CcOOf+L4C/771/vu1rAQDn3D8A0ALwee/9OyfPfRzAU+/9JyY3z/ve+48W6PpeRY6NVDdB\nxmavP40C/A2X3Yx2WTZl8d8N4C+899/x3g8B/Aauf8ki4VCgqY/3/isA9E3ofQA+Nzn/HIB/tNGL\nIiLXBxRkI1Xv/Rve+69PzlsAvgngFRTkbxi5vo1tRrupL/rbAfwVPf4ubn7JouAB/L5z7mvOuZ/d\n9sVEeCCblkx2MXqw5esJUbiNVGmz1z8E8LBof8NtbEZbGAtXAN7jvf97AP4hgH8xcWWLTtHWYgu3\nkWpgs1f9N9vq33Bbm9FuSvh/DeAH6PErk+cKg/f+e5PjmwB+F9fTk6Lx2Dn3EEjmiN/f8vWk8N6/\nSdsmfRrAD23zekKbvaJAf8PYZrSb+BtuSvhfA/B3nXPvcM5VAHwAwJc29Nkzcc41JndeOOeaAH4c\nwJ9u96oAXM/1eL73JQAfmpz/FIAv6jdsmNT1TYQk/CS2/zf8VQB/5r3/FD1XpL/h1PVt6m+4scy9\nybLEp3B9s/mM9/6XNvLBOXDO/W1cW3mP663Df33b1+ec+wKAUwAnAB4DeBXAfwLw2wD+FoDvAHi/\n9/5Fga7vR5BjI9UNXV9ss9evAvgtbPlvuOxmtEt/vqXsGsbuYcE9w9hBTPiGsYOY8A1jBzHhG8YO\nYsI3jB3EhG8YO4gJ3zB2EBO+Yewg/x84r3AjlRdk9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6e38d10438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "digit = train_images[10]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Chapter summary\n",
    "\n",
    " Learning means finding a combination of model parameters that mini- mizes a loss function for a given set of training data samples and their cor- responding targets.\n",
    "\n",
    " Learning happens by drawing random batches of data samples and their targets, and computing the gradient of the network parameters with respect to the loss on the batch. The network parameters are then moved a bit (the magnitude of the move is defined by the learning rate) in the opposite direction from the gradient.\n",
    "\n",
    " The entire learning process is made possible by the fact that neural net- works are chains of differentiable tensor operations, and thus it’s possible to apply the chain rule of derivation to find the gradient function map- ping the current parameters and current batch of data to a gradient value.\n",
    "\n",
    " Two key concepts you’ll see frequently in future chapters are loss and opti- mizers. These are the two things you need to define before you begin feed- ing data into a network.\n",
    "\n",
    " The loss is the quantity you’ll attempt to minimize during training, so it should represent a measure of success for the task you’re trying to solve.\n",
    "\n",
    " The optimizer specifies the exact way in which the gradient of the loss will be used to update parameters: for instance, it could be the RMSProp opti- mizer, SGD with momentum, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
